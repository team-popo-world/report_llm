from langchain_huggingface import HuggingFaceEmbeddings
from langchain.schema import Document
from qdrant_client import QdrantClient
from langchain.vectorstores import Qdrant
from utils.load_db import load_userId
from utils.json_to_natural_language import format_natural_language_summary
# from utils.json_to_documents import json_to_documents
import requests
import pandas as pd
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(override=True)

# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
host = os.getenv("QDRANT_HOST")
# port = os.getenv("QDRANT_PORT")

print(f"Qdrant ì—°ê²°: {host}")

# â¶ Qdrant ì„œë²„ ì—°ê²° (ì„œë²„ ì£¼ì†Œë¥¼ ë°”ê¾¸ì„¸ìš”)
client = QdrantClient(url=host, prefer_grpc=False)

# ì°¸ê³ ìë£Œ dagë¥¼ ì´ìš©í•´ì„œ ìš°ë¦¬ ì•„ì´ì˜ ê²°ê³¼ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë ˆí¬íŠ¸ ì‘ì„±í•˜ê¸°

# ì „ì²´ ìœ ì €ì— ëŒ€í•´ì„œ updateí•´ì•¼ í•˜ë¯€ë¡œ sqlì—ì„œ userIdë§Œ ë¶ˆëŸ¬ì™€ì„œ ì €ì¥
# userId(str)
# report_data(json)

# SQLì—ì„œ ì „ì²´ ë°ì´í„° ë°›ì•„ì˜¤ê¸°
user_list = load_userId()

# print(user_list)

"""
ë°ì´í„° í”„ë ˆì„
# userId
# type(str, ì–´ë–¤ ë¶„ì•¼ì¸ì§€( ex)invest, quest, ...))
# graph_name(str; ì–´ë–¤ ê·¸ë˜í”„ì¸ì§€)
# graph_data(json; ê·¸ë˜í”„ ê·¸ë¦¬ëŠ”ë° ì‚¬ìš©í•œ jsoníŒŒì¼)
# graph_summary(str; ê·¸ë˜í”„ í¬ë§·íŒ…í•œ ê²°ê³¼)
"""

# apië¡œ ê·¸ë˜í”„ ë³„ë¡œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
graph_list = ["avg_stay_time", "buy_ratio", "sell_ratio", "buy_sell_ratio", "bet_ratio", "avg_cash_ratio"]

# invest_merged_df = pd.DataFrame()  # ì´ˆê¸° ë³‘í•©ìš© ë°ì´í„°í”„ë ˆì„

##########################################í…ŒìŠ¤íŠ¸ìš©#############################################
# userId = "956f51a8-d6a0-4a12-a22b-9da3cdffc879"
# for graphName in graph_list:
#     invest_url = f"http://43.203.175.69:8002/api/invest/{graphName}/week?userId={userId}"
#     headers = {"Content-Type": "application/json"}

#     response = requests.get(invest_url, headers=headers)

#     if response.status_code == 200:
#         # print(response.json())  # ì‘ë‹µ ë°ì´í„°
#         data = response.json()  # JSON -> Python ê°ì²´ (list of dict)
#         df = pd.DataFrame(data)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ DataFrameìœ¼ë¡œ ë³€í™˜
#         print(df.head())  # í™•ì¸ìš©
#         if df.empty:
#             print(f"ğŸ“­ [EMPTY] userId: {userId}, graph: {graphName}")
#             continue  # ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê³  ë‹¤ìŒìœ¼ë¡œ

#         print(f"âœ… [RECEIVED] userId: {userId}, graph: {graphName}, rows: {len(df)}")

#         # ë³‘í•© ì²˜ë¦¬
#         if invest_merged_df.empty:
#             invest_merged_df = df
#         else:
#             invest_merged_df = pd.merge(invest_merged_df, df, on=["userId", "startedAt"], how="inner")

#     else:
#         print("ì—ëŸ¬ ë°œìƒ:", response.status_code)
#         print("ì—ëŸ¬ ë‚´ìš©:", response.text)

# print(invest_merged_df.head())
# print("invest_merged_df columns:", invest_merged_df.columns)
# invest_merged_df.to_csv("data/íŠ¹ì •ì‚¬ëŒ_invest_api_ë¶ˆëŸ¬ì™€ì„œ_ë³‘í•©.csv", index=False, encoding="utf-8")
#####################################################################################################

# invest ìª½ api ë¶ˆëŸ¬ì˜¤ê¸°
# for userId in user_list:
#     for graphName in graph_list:
#             invest_url = f"http://43.203.175.69:8002/api/invest/{graphName}/week?userId={userId}"
#             headers = {"Content-Type": "application/json"}

#             response = requests.get(invest_url, headers=headers)

#             if response.status_code == 200:
#                 # print(response.json())  # ì‘ë‹µ ë°ì´í„°
#                 data = response.json()  # JSON -> Python ê°ì²´ (list of dict)
#                 df = pd.DataFrame(data)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ DataFrameìœ¼ë¡œ ë³€í™˜
#                 print(df.head())  # í™•ì¸ìš©
#                 if df.empty:
#                     print(f"ğŸ“­ [EMPTY] userId: {userId}, graph: {graphName}")
#                     continue  # ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê³  ë‹¤ìŒìœ¼ë¡œ

#                 print(f"âœ… [RECEIVED] userId: {userId}, graph: {graphName}, rows: {len(df)}")

#                 # ë³‘í•© ì²˜ë¦¬
#                 if merged_df.empty:
#                     merged_df = df
#                 else:
#                     merged_df = pd.merge(merged_df, df, on=["userId", "startedAt"], how="inner")

#             else:
#                 print("ì—ëŸ¬ ë°œìƒ:", response.status_code)
#                 print("ì—ëŸ¬ ë‚´ìš©:", response.text)

# quest_url = f"http://43.203.175.69:8000/graph/{}/{}?userId={userId}"
# shop_url = f"http://43.203.175.69:8001/api/{}/{}?userId={userId}"

# invest_merged_df = pd.read_csv("data/íŠ¹ì •ì‚¬ëŒ_invest_api_ë¶ˆëŸ¬ì™€ì„œ_ë³‘í•©.csv")

# # ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ
# formatted_df = format_natural_language_summary(invest_merged_df)

# # ğŸ“ ì €ì¥
# formatted_df.to_csv("data/natural_format_data.csv", index=False)

format_df = pd.read_csv("data/natural_format_data.csv")

documents = [
    Document(
        page_content=row["formatText"],
        metadata={"userId": row["userId"]}
    )
    for _, row in format_df.iterrows()
]

# Document(
#     page_content=f"""
#     ì‚¬ìš©ì ID: {row['userId']}
#     ê²Œì„ ì‹œì‘ ì‹œê°: {row['startedAt']}
#     ìš”ì•½ ì„¤ëª…: {row['formatText']}
#     """.strip(),
#     metadata={"userId": row["userId"]}
# )

embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Qdrant ë²¡í„° DB ìƒì„± ë° ì €ì¥
qdrant = Qdrant.from_documents(
    documents=documents,
    embedding=embedding,
    client=client,
    collection_name="my_user_summaries"
)

query = "ê³ ìœ„í—˜ ìì‚° ì„ í˜¸í•˜ëŠ” ì•„ì´ë“¤"
results = qdrant.similarity_search(query, k=3)

for doc in results:
    print(doc.metadata["userId"], "\n", doc.page_content)

# json = load_mongo(collection_name="graph1_all_history")

# documents = json_to_documents(json)

# # ë²¡í„° DBì— ì €ì¥
# vector_db = Chroma.from_documents(
#   documents, 
#   embeddings=embeddings, 
#   persist_directory="./chroma_db"
# )

# # ì´í›„ RAGì— í™œìš©
# retriever = vector_db.as_retriever()
# retriever.get_relevant_documents("ìµœê·¼ íˆ¬ì íŠ¸ë Œë“œëŠ”?")